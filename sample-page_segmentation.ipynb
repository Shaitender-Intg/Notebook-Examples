{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import glob\n",
    "import os\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "# Sklearn imports\n",
    "import pandas\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import sklearn.svm\n",
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n'/data/workspace/lexpredict-contraxsuite-samples/agreements/construction/1000694_2002-03-15_AGREEMENT OF LEASE-W.M.RICKMAN CONSTRUCTION CO..txt': [66,\\n  129,\\n  212,\\n  294,\\n  380,\\n  472,\\n  565,\\n  648,\\n  741,\\n  843,\\n  949,\\n  1043,\\n  1133],\\n '/data/workspace/lexpredict-contraxsuite-samples/agreements/construction/1002047_1999-08-31_CONSTRUCTION MANAGEMENT AGREEMENT.txt': [10,\\n  59,\\n  112,\\n  169,\\n  217,\\n  289,\\n  368,\\n  441,\\n  507,\\n  576,\\n  636,\\n  695,\\n  773,\\n  849,\\n  930,\\n  997,\\n  1071,\\n  1120,\\n  1141,\\n  1160,\\n  1221,\\n  1289,\\n  1303,\\n  1323,\\n  1381,\\n  1457,\\n  1528,\\n  1585,\\n  1650,\\n  1728,\\n  1786,\\n  1837,\\n  1900,\\n  1951,\\n  2004,\\n  2059,\\n  2117],\\n '/data/workspace/lexpredict-contraxsuite-samples/agreements/construction/1065837_2012-02-29_CONSTRUCTION LOAN AGREEMENT.txt': [308,\\n  348,\\n  386,\\n  425,\\n  469,\\n  507,\\n  547,\\n  588,\\n  626,\\n  664,\\n  702,\\n  742,\\n  781,\\n  821,\\n  862,\\n  902,\\n  942,\\n  982,\\n  1022,\\n  1062,\\n  1102,\\n  1142,\\n  1182,\\n  1223,\\n  1260,\\n  1301,\\n  1341,\\n  1380,\\n  1422,\\n  1460,\\n  1505,\\n  1545,\\n  1584,\\n  1626,\\n  1664,\\n  1706,\\n  1747,\\n  1763,\\n  1827,\\n  1902,\\n  1942,\\n  1964,\\n  2007,\\n  2058,\\n  2104,\\n  2155,\\n  2204,\\n  2253,\\n  2301,\\n  2344,\\n  2389,\\n  2430,\\n  2470,\\n  2513,\\n  2525,\\n  2710,\\n  5412,\\n  5456,\\n  5513,\\n  5557,\\n  5600,\\n  5642,\\n  5679,\\n  5700,\\n  5752,\\n  5786,\\n  5797,\\n  5836,\\n  5849,\\n  5873,\\n  5917,\\n  5959,\\n  6000,\\n  6037,\\n  6070,\\n  6141,\\n  6171,\\n  6202,\\n  6240,\\n  6293,\\n  6338,\\n  6377,\\n  6417,\\n  6460,\\n  6493,\\n  6530,\\n  6599,\\n  6660],\\n '/data/workspace/lexpredict-contraxsuite-samples/agreements/employment/1007297_1999-05-17_EMPLOYMENT AGREEMENT WITH MARK STEVENS.txt': \\n    [10, 75, 78],\\n '/data/workspace/lexpredict-contraxsuite-samples/agreements/employment/1002658_2001-11-14_AMENDMENT TO EMPLOYMENT AGREEMENT  STEVEN R. KIM.txt':\\n    [9, 107],\\n '/data/workspace/lexpredict-contraxsuite-samples/agreements/employment/1002554_1996-05-14_EMPLOYMENT AGREEMENT DATED MARCH 8, 1996.txt':\\n    [11, 60, 63],\\n '/data/workspace/lexpredict-contraxsuite-samples/agreements/software_license/1000297_1999-03-16_SOFTWARE LICENSE AGREEMENT.txt':\\n    [10, 64, 65, 123, 124, 182, 183, 237, 238, 301, 302, 359, 360, 421, 422, 482, 483, 528, 529, 551, 552, 607, 608, 643, 644, 698, 699, 748, 749, 793],\\n'/data/workspace/lexpredict-contraxsuite-samples/agreements/employment/701719_2007-05-31_EMPLOYMENT AGREEMENT - J.BENSON.txt':\\n    [119, 255, 384, 439, 449, 516],\\n'/data/workspace/lexpredict-contraxsuite-samples/agreements/employment/1013488_2005-09-07_EMPLOYMENT AGREEMENT OF GREGORY S. LEVIN.txt':\\n    [79, 116, 147],\\n\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "'/data/workspace/lexpredict-contraxsuite-samples/agreements/construction/1000694_2002-03-15_AGREEMENT OF LEASE-W.M.RICKMAN CONSTRUCTION CO..txt': [66,\n",
    "  129,\n",
    "  212,\n",
    "  294,\n",
    "  380,\n",
    "  472,\n",
    "  565,\n",
    "  648,\n",
    "  741,\n",
    "  843,\n",
    "  949,\n",
    "  1043,\n",
    "  1133],\n",
    " '/data/workspace/lexpredict-contraxsuite-samples/agreements/construction/1002047_1999-08-31_CONSTRUCTION MANAGEMENT AGREEMENT.txt': [10,\n",
    "  59,\n",
    "  112,\n",
    "  169,\n",
    "  217,\n",
    "  289,\n",
    "  368,\n",
    "  441,\n",
    "  507,\n",
    "  576,\n",
    "  636,\n",
    "  695,\n",
    "  773,\n",
    "  849,\n",
    "  930,\n",
    "  997,\n",
    "  1071,\n",
    "  1120,\n",
    "  1141,\n",
    "  1160,\n",
    "  1221,\n",
    "  1289,\n",
    "  1303,\n",
    "  1323,\n",
    "  1381,\n",
    "  1457,\n",
    "  1528,\n",
    "  1585,\n",
    "  1650,\n",
    "  1728,\n",
    "  1786,\n",
    "  1837,\n",
    "  1900,\n",
    "  1951,\n",
    "  2004,\n",
    "  2059,\n",
    "  2117],\n",
    " '/data/workspace/lexpredict-contraxsuite-samples/agreements/construction/1065837_2012-02-29_CONSTRUCTION LOAN AGREEMENT.txt': [308,\n",
    "  348,\n",
    "  386,\n",
    "  425,\n",
    "  469,\n",
    "  507,\n",
    "  547,\n",
    "  588,\n",
    "  626,\n",
    "  664,\n",
    "  702,\n",
    "  742,\n",
    "  781,\n",
    "  821,\n",
    "  862,\n",
    "  902,\n",
    "  942,\n",
    "  982,\n",
    "  1022,\n",
    "  1062,\n",
    "  1102,\n",
    "  1142,\n",
    "  1182,\n",
    "  1223,\n",
    "  1260,\n",
    "  1301,\n",
    "  1341,\n",
    "  1380,\n",
    "  1422,\n",
    "  1460,\n",
    "  1505,\n",
    "  1545,\n",
    "  1584,\n",
    "  1626,\n",
    "  1664,\n",
    "  1706,\n",
    "  1747,\n",
    "  1763,\n",
    "  1827,\n",
    "  1902,\n",
    "  1942,\n",
    "  1964,\n",
    "  2007,\n",
    "  2058,\n",
    "  2104,\n",
    "  2155,\n",
    "  2204,\n",
    "  2253,\n",
    "  2301,\n",
    "  2344,\n",
    "  2389,\n",
    "  2430,\n",
    "  2470,\n",
    "  2513,\n",
    "  2525,\n",
    "  2710,\n",
    "  5412,\n",
    "  5456,\n",
    "  5513,\n",
    "  5557,\n",
    "  5600,\n",
    "  5642,\n",
    "  5679,\n",
    "  5700,\n",
    "  5752,\n",
    "  5786,\n",
    "  5797,\n",
    "  5836,\n",
    "  5849,\n",
    "  5873,\n",
    "  5917,\n",
    "  5959,\n",
    "  6000,\n",
    "  6037,\n",
    "  6070,\n",
    "  6141,\n",
    "  6171,\n",
    "  6202,\n",
    "  6240,\n",
    "  6293,\n",
    "  6338,\n",
    "  6377,\n",
    "  6417,\n",
    "  6460,\n",
    "  6493,\n",
    "  6530,\n",
    "  6599,\n",
    "  6660],\n",
    " '/data/workspace/lexpredict-contraxsuite-samples/agreements/employment/1007297_1999-05-17_EMPLOYMENT AGREEMENT WITH MARK STEVENS.txt': \n",
    "    [10, 75, 78],\n",
    " '/data/workspace/lexpredict-contraxsuite-samples/agreements/employment/1002658_2001-11-14_AMENDMENT TO EMPLOYMENT AGREEMENT  STEVEN R. KIM.txt':\n",
    "    [9, 107],\n",
    " '/data/workspace/lexpredict-contraxsuite-samples/agreements/employment/1002554_1996-05-14_EMPLOYMENT AGREEMENT DATED MARCH 8, 1996.txt':\n",
    "    [11, 60, 63],\n",
    " '/data/workspace/lexpredict-contraxsuite-samples/agreements/software_license/1000297_1999-03-16_SOFTWARE LICENSE AGREEMENT.txt':\n",
    "    [10, 64, 65, 123, 124, 182, 183, 237, 238, 301, 302, 359, 360, 421, 422, 482, 483, 528, 529, 551, 552, 607, 608, 643, 644, 698, 699, 748, 749, 793],\n",
    "'/data/workspace/lexpredict-contraxsuite-samples/agreements/employment/701719_2007-05-31_EMPLOYMENT AGREEMENT - J.BENSON.txt':\n",
    "    [119, 255, 384, 439, 449, 516],\n",
    "'/data/workspace/lexpredict-contraxsuite-samples/agreements/employment/1013488_2005-09-07_EMPLOYMENT AGREEMENT OF GREGORY S. LEVIN.txt':\n",
    "    [79, 116, 147],\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_break_positions = {\n",
    "'/data/workspace/lexpredict-contraxsuite-core/test_data/1205332_2008-05-08_3':\n",
    "    [122, 247, 364, 474, 582, 709, 817],\n",
    "'/data/workspace/lexpredict-contraxsuite-core/test_data/1007273_2014-03-11_2':\n",
    "    [63, 114, 161, 209, 246, 288, 332, 383, 417, 457, 512, 561, 605, 646, 689, 740, 790, 838, 882, 929, 980, 1033,\n",
    "    1073, 1122, 1175, 1221, 1270, 1323, 1350],\n",
    "'/data/workspace/lexpredict-contraxsuite-core/test_data/1001840_1997-08-28_CREDIT AGREEMENT.txt':\n",
    "    [10, 57, 102, 150, 196, 243, 288, 335, 384, 432, 479, 525, 573, 618, 663, 710, 756, 803, 849, 889]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_document_distribution(text, characters=string.printable, norm=True):\n",
    "    \"\"\"\n",
    "    Build document distribution based on fixed character and optionally norm to unit.\n",
    "    \"\"\"\n",
    "    # Build character vector\n",
    "    v = {}\n",
    "    for c in characters:\n",
    "        v[\"doc_char_{0}\".format(c)] = text.count(c)\n",
    "\n",
    "    # Norm if requested\n",
    "    if norm:\n",
    "        total = float(sum(v.values()))\n",
    "        for k in v.keys():\n",
    "            v[k] = v[k] / total \n",
    "\n",
    "    return  v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_page_break_features(lines, line_id, line_window_pre, line_window_post, characters=string.printable,\n",
    "                             include_doc=None):\n",
    "    \"\"\"\n",
    "    Build a feature vector for a given line ID with given parameters.\n",
    "    \"\"\"\n",
    "    # Feature vector\n",
    "    v = {}\n",
    "    \n",
    "    # Check start offset\n",
    "    if line_id < line_window_pre:\n",
    "        line_window_pre = line_id\n",
    "        \n",
    "    # Check final offset\n",
    "    if (line_id + line_window_post) >= len(lines):\n",
    "        line_window_post = len(lines) - line_window_post - 1\n",
    "    \n",
    "    # Iterate through window\n",
    "    for i in range (-line_window_pre, line_window_post+1):\n",
    "        try:\n",
    "            line = lines[line_id+i]\n",
    "        except IndexError as e:\n",
    "            continue\n",
    "        \n",
    "        # Count length\n",
    "        v[\"line_len_{0}\".format(i)] = len(line)\n",
    "        \n",
    "        # Count characters\n",
    "        v[\"line_n_alpha_{0}\".format(i)] = sum([1 for c in line if unicodedata.category(c).startswith(\"L\")])\n",
    "        v[\"line_n_number_{0}\".format(i)] = sum([1 for c in line if unicodedata.category(c).startswith(\"N\")])\n",
    "        v[\"line_n_punct_{0}\".format(i)] = sum([1 for c in line if unicodedata.category(c).startswith(\"P\")])\n",
    "        v[\"line_n_whitespace_{0}\".format(i)] = sum([1 for c in line if unicodedata.category(c).startswith(\"Z\")])\n",
    "    \n",
    "    # Simple checks\n",
    "    v[\"page\"] = 1 if \"page\" in line else 0\n",
    "    v[\"PAGE\"] = 1 if \"PAGE\" in line else 0\n",
    "    v[\"Page\"] = 1 if \"Page\" in line else 0\n",
    "    v[\"sw_page\"] = 1 if line.strip().lower().startswith(\"page\") else 0\n",
    "    v[\"sw_pg\"] = 1 if line.strip().lower().startswith(\"pg\") else 0\n",
    "    v[\"first_char_punct\"] = (line.strip()[0] in string.punctuation) if len(line.strip()) > 0 else False\n",
    "    v[\"last_char_punct\"] = (line.strip()[-1] in string.punctuation) if len(line.strip()) > 0 else False\n",
    "    v[\"first_char_number\"] = (line.strip()[0] in string.digits) if len(line.strip()) > 0 else False\n",
    "    v[\"last_char_number\"] = (line.strip()[-1] in string.digits) if len(line.strip()) > 0 else False\n",
    "    \n",
    "    # Build character vector\n",
    "    for c in characters:\n",
    "        v[\"char_{0}\".format(c)] = lines[line_id].count(c)\n",
    "    \n",
    "    # Add doc if requested\n",
    "    if include_doc:\n",
    "        v.update(include_doc)\n",
    "    \n",
    "    return v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "line_window_pre = 3\n",
    "line_window_post = 3\n",
    "\n",
    "# Setup feature and target data\n",
    "feature_data = []\n",
    "target_data = []\n",
    "\n",
    "# Iterate through files and test\n",
    "for file_name in sorted(list(page_break_positions.keys())):\n",
    "    # Read and get doc distribution\n",
    "    file_buffer = open(file_name, \"rb\").read().decode(\"utf-8\")\n",
    "    doc_distribution=build_document_distribution(file_buffer)\n",
    "    \n",
    "    # Split to lines and iterate\n",
    "    file_lines = file_buffer.splitlines()\n",
    "    for line_id in range(len(file_lines)):\n",
    "        feature_data.append(build_page_break_features(file_lines, line_id, line_window_pre, line_window_post, include_doc=doc_distribution))\n",
    "        target_data.append(1 if (line_id) in page_break_positions[file_name] else 0)\n",
    "        if target_data[-1] == 1:\n",
    "            #print((file_name, line_id, target_data[-1]))\n",
    "            #print(file_lines[line_id])\n",
    "            pass\n",
    "\n",
    "# Convert to DF\n",
    "feature_df = pandas.DataFrame(feature_data).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3285, 244)\n",
      "3285\n"
     ]
    }
   ],
   "source": [
    "print(feature_df.shape)\n",
    "print(len(target_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3229\n",
      "          1       1.00      1.00      1.00        56\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3285\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model_svc = sklearn.svm.SVC(kernel='linear', probability=True)\n",
    "model_svc.fit(feature_df, target_data)\n",
    "\n",
    "# Assess model\n",
    "predicted_svc = model_svc.predict(feature_df)\n",
    "print(sklearn.metrics.classification_report(target_data, predicted_svc))\n",
    "print(sklearn.metrics.f1_score(target_data, predicted_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3229\n",
      "          1       1.00      1.00      1.00        56\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3285\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model_log = sklearn.linear_model.LogisticRegressionCV()\n",
    "model_log.fit(feature_df, target_data)\n",
    "\n",
    "# Assess model\n",
    "predicted_log = model_log.predict(feature_df)\n",
    "print(sklearn.metrics.classification_report(target_data, predicted_log))\n",
    "print(sklearn.metrics.f1_score(target_data, predicted_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3229\n",
      "          1       1.00      1.00      1.00        56\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3285\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model_et = sklearn.ensemble.ExtraTreesClassifier(n_estimators=10)\n",
    "model_et.fit(feature_df, target_data)\n",
    "\n",
    "# Assess model\n",
    "predicted_et = model_et.predict(feature_df)\n",
    "print(sklearn.metrics.classification_report(target_data, predicted_et))\n",
    "print(sklearn.metrics.f1_score(target_data, predicted_et))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3229\n",
      "          1       1.00      1.00      1.00        56\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3285\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model_dt = sklearn.tree.DecisionTreeClassifier()\n",
    "model_dt.fit(feature_df, target_data)\n",
    "\n",
    "# Assess model\n",
    "predicted_dt = model_et.predict(feature_df)\n",
    "print(sklearn.metrics.classification_report(target_data, predicted_dt))\n",
    "print(sklearn.metrics.f1_score(target_data, predicted_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3229\n",
      "          1       1.00      1.00      1.00        56\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3285\n",
      "\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/workspace/lexpredict-contraxsuite-core/env/lib/python3.5/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model_vote = sklearn.ensemble.VotingClassifier(estimators=[\n",
    "    ('log', model_log),\n",
    "    ('et', model_et)], voting='soft')\n",
    "model_vote.fit(feature_df, target_data)\n",
    "\n",
    "# Assess model\n",
    "predicted_vote = model_vote.predict(feature_df)\n",
    "print(sklearn.metrics.classification_report(target_data, predicted_vote))\n",
    "print(sklearn.metrics.f1_score(target_data, predicted_vote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['page_segmenter.pickle']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set production model\n",
    "from sklearn.externals import joblib\n",
    "model = model_dt\n",
    "model.line_window_pre = line_window_pre\n",
    "model.line_window_post = line_window_post\n",
    "model.doc_distribution = True\n",
    "joblib.dump(model, \"page_segmenter.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/workspace/lexpredict-contraxsuite-core/test_data/1001840_1997-08-28_CREDIT AGREEMENT.txt\n",
      "/data/workspace/lexpredict-contraxsuite-core/test_data/1007273_2014-03-11_2\n",
      "/data/workspace/lexpredict-contraxsuite-core/test_data/1205332_2008-05-08_3\n"
     ]
    }
   ],
   "source": [
    "# Test OOS\n",
    "file_list = sorted(glob.glob(\"/data/workspace/lexpredict-contraxsuite-core/test_data/*\"))\n",
    "test_lines = []\n",
    "test_feature_data = []\n",
    "\n",
    "for file_name in file_list:\n",
    "    if file_name.endswith(\".gz\") or file_name.endswith(\".tar\"):\n",
    "        continue\n",
    "    else:\n",
    "        print(file_name)\n",
    "    file_buffer = open(file_name, \"rb\").read().decode(\"utf-8\")\n",
    "    file_lines = file_buffer.splitlines()\n",
    "    doc_distribution = build_document_distribution(file_buffer)\n",
    "    for line_id in range(len(file_lines)):\n",
    "        test_feature_data.append(build_page_break_features(file_lines, line_id, line_window_pre, line_window_post, include_doc=doc_distribution))\n",
    "        test_lines.append((file_name, line_id, file_lines[line_id]))\n",
    "    \n",
    "# Predict page breaks\n",
    "test_feature_df = pandas.DataFrame(test_feature_data).fillna(-1)\n",
    "test_predicted_lines = model_dt.predict_proba(test_feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_name': '/data/workspace/lexpredict-contraxsuite-core/test_data/1007273_2014-03-11_2',\n",
       "  'line': '    \\t1',\n",
       "  'line_id': 63,\n",
       "  'prob_break': 1.0,\n",
       "  'prob_text': 0.0},\n",
       " {'file_name': '/data/workspace/lexpredict-contraxsuite-core/test_data/1007273_2014-03-11_2',\n",
       "  'line': '    \\t2',\n",
       "  'line_id': 114,\n",
       "  'prob_break': 1.0,\n",
       "  'prob_text': 0.0},\n",
       " {'file_name': '/data/workspace/lexpredict-contraxsuite-core/test_data/1007273_2014-03-11_2',\n",
       "  'line': '    \\t3',\n",
       "  'line_id': 161,\n",
       "  'prob_break': 1.0,\n",
       "  'prob_text': 0.0},\n",
       " {'file_name': '/data/workspace/lexpredict-contraxsuite-core/test_data/1007273_2014-03-11_2',\n",
       "  'line': '    \\t4',\n",
       "  'line_id': 209,\n",
       "  'prob_break': 1.0,\n",
       "  'prob_text': 0.0},\n",
       " {'file_name': '/data/workspace/lexpredict-contraxsuite-core/test_data/1007273_2014-03-11_2',\n",
       "  'line': '    \\t5',\n",
       "  'line_id': 246,\n",
       "  'prob_break': 1.0,\n",
       "  'prob_text': 0.0}]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pandas.concat([pandas.DataFrame(test_lines), pandas.DataFrame(test_predicted_lines)], axis=1)\n",
    "test_df.columns = [\"file_name\", \"line_id\", \"line\", \"prob_text\", \"prob_break\"]\n",
    "test_df.loc[test_df.loc[:, \"prob_break\"] >= 0.5, :].head().to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>line_id</th>\n",
       "      <th>line</th>\n",
       "      <th>prob_text</th>\n",
       "      <th>prob_break</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>/data/workspace/lexpredict-contraxsuite-core/t...</td>\n",
       "      <td>96</td>\n",
       "      <td>the Effective Date (the date set forth on Page...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>/data/workspace/lexpredict-contraxsuite-core/t...</td>\n",
       "      <td>122</td>\n",
       "      <td>Page 1 of 7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>/data/workspace/lexpredict-contraxsuite-core/t...</td>\n",
       "      <td>247</td>\n",
       "      <td>Page 2 of 7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>/data/workspace/lexpredict-contraxsuite-core/t...</td>\n",
       "      <td>364</td>\n",
       "      <td>Page 3 of 7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>/data/workspace/lexpredict-contraxsuite-core/t...</td>\n",
       "      <td>474</td>\n",
       "      <td>Page 4 of 7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>/data/workspace/lexpredict-contraxsuite-core/t...</td>\n",
       "      <td>582</td>\n",
       "      <td>Page 5 of 7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>/data/workspace/lexpredict-contraxsuite-core/t...</td>\n",
       "      <td>709</td>\n",
       "      <td>Page 6 of 7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>/data/workspace/lexpredict-contraxsuite-core/t...</td>\n",
       "      <td>817</td>\n",
       "      <td>Page 7 of 7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file_name  line_id  \\\n",
       "96    /data/workspace/lexpredict-contraxsuite-core/t...       96   \n",
       "1664  /data/workspace/lexpredict-contraxsuite-core/t...      122   \n",
       "1789  /data/workspace/lexpredict-contraxsuite-core/t...      247   \n",
       "1906  /data/workspace/lexpredict-contraxsuite-core/t...      364   \n",
       "2016  /data/workspace/lexpredict-contraxsuite-core/t...      474   \n",
       "2124  /data/workspace/lexpredict-contraxsuite-core/t...      582   \n",
       "2251  /data/workspace/lexpredict-contraxsuite-core/t...      709   \n",
       "2359  /data/workspace/lexpredict-contraxsuite-core/t...      817   \n",
       "\n",
       "                                                   line  prob_text  prob_break  \n",
       "96    the Effective Date (the date set forth on Page...        1.0         0.0  \n",
       "1664                                        Page 1 of 7        0.0         1.0  \n",
       "1789                                        Page 2 of 7        0.0         1.0  \n",
       "1906                                        Page 3 of 7        0.0         1.0  \n",
       "2016                                        Page 4 of 7        0.0         1.0  \n",
       "2124                                        Page 5 of 7        0.0         1.0  \n",
       "2251                                        Page 6 of 7        0.0         1.0  \n",
       "2359                                        Page 7 of 7        0.0         1.0  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df[\"line\"].str.contains(\"Page\"), :].sort_values(\"prob_break\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
