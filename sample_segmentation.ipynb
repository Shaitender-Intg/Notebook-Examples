{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import glob\n",
    "import os\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "# Sklearn imports\n",
    "import numpy\n",
    "import pandas\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import sklearn.svm\n",
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paragraph_break_positions = {'../../data/samples/lexpredict-contraxsuite-samples-master/agreements/construction/1000694_2002-03-15_AGREEMENT OF LEASE-W.M.RICKMAN CONSTRUCTION CO..txt':\n",
    "    [7, 50, 71, 106, 130, 152, 172, 202, 228, 250, 708, 745, 764, 795, 889, 909, 953, 986, 1012, 1042, 1061, 1299, 1404, 1496, 1653, 1690, 1709, 1734, 1763, 1788, 1806, 1880, 2039, 2053, 2075, \n",
    "    2463, 2918, 4037, 4326, 4591, 4610, 4999, 5721, 6334, 6622, 7285, 7899, 7920, 8006, 8180, \n",
    "    8349, 8355, 8871, 10413, 10908, 10931, 11038, 11368, 11639, 11917, 12921, 13930, 13954, \n",
    "    14611, 15232, 15931, 16424, 17286, 17304, 17407, 17879, 18295, 19791, 20472, 21455, 22707,\n",
    "    23126, 23615, 23910, 23931, 24538, 24569, 24650, 25105, 25539, 25848, 25873, 26087, 27182, 27203, \n",
    "    27365, 27576, 27672, 27778, 27999, 28059, 28181, 28316, 28458, 28827, 29247, 29546, 29565, \n",
    "    29706, 29840,  30130, 30747, 30767, 30772, 31113, 31421, 32240, 32259, 32385, 33874, 33994],\n",
    "                             '../../data/samples/lexpredict-contraxsuite-samples-master/agreements/employment/1000736_2005-05-10_AMENDMENT TO EMPLOYMENT AGREEMENT.txt':\n",
    "                             [7, 44, 58, 93, 317, 493, 606, 816, 1007, 1159, 1330, 1557,  2022, 2205, 2385, 3024, 3231, 3371, 3435],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paragraph_characters = []\n",
    "paragraph_characters.extend(string.whitespace)\n",
    "paragraph_characters.extend(string.punctuation)\n",
    "\n",
    "def build_paragraph_start_features(text, position, position_window_pre, position_window_post, characters=paragraph_characters):\n",
    "    \"\"\"\n",
    "    Build a feature vector for a given line ID with given parameters.\n",
    "    \"\"\"\n",
    "    # Feature vector\n",
    "    v = {}\n",
    "    \n",
    "    # Check start offset\n",
    "    if position < position_window_pre:\n",
    "        position_window_pre = position\n",
    "        \n",
    "    # Iterate through window\n",
    "    for i in range (-position_window_pre, position_window_post+1):\n",
    "        # Character\n",
    "        try:\n",
    "            pos_char = text[position+i]\n",
    "            \n",
    "            # Count characters\n",
    "            v[\"char_is_alpha_{0}\".format(i)] = 1 if unicodedata.category(pos_char).startswith(\"L\") else 0\n",
    "            v[\"char_is_number_{0}\".format(i)] = 1 if unicodedata.category(pos_char).startswith(\"N\") else 0\n",
    "            v[\"char_is_punct_{0}\".format(i)] = 1 if unicodedata.category(pos_char).startswith(\"P\") else 0\n",
    "            v[\"char_is_whitespace_{0}\".format(i)] = 1 if unicodedata.category(pos_char).startswith(\"Z\") else 0\n",
    "\n",
    "            # Build character vector\n",
    "            for c in characters:\n",
    "                v[\"char_{0}_{1}\".format(c, i)] = 1 if pos_char == c else 0\n",
    "\n",
    "        except IndexError as e:\n",
    "            v[\"char_is_alpha_{0}\".format(i)] = None\n",
    "            v[\"char_is_number_{0}\".format(i)] = None\n",
    "            v[\"char_is_punct_{0}\".format(i)] = None\n",
    "            v[\"char_is_whitespace_{0}\".format(i)] = None\n",
    "            \n",
    "            # Build character vector\n",
    "            for c in characters:\n",
    "                v[\"char_{0}_{1}\".format(c, i)] = None\n",
    "\n",
    "    # Build character vector\n",
    "    for c in characters:\n",
    "        v[\"char_{0}\".format(c)] = 1 if text[position] == c else 0\n",
    "        \n",
    "    return v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'char_\\t': 0,\n",
       " 'char_\\t_-1': 0,\n",
       " 'char_\\t_-2': 0,\n",
       " 'char_\\t_-3': 0,\n",
       " 'char_\\t_0': 0,\n",
       " 'char_\\t_1': 0,\n",
       " 'char_\\t_2': 0,\n",
       " 'char_\\t_3': 0,\n",
       " 'char_\\n': 1,\n",
       " 'char_\\n_-1': 0,\n",
       " 'char_\\n_-2': 0,\n",
       " 'char_\\n_-3': 0,\n",
       " 'char_\\n_0': 1,\n",
       " 'char_\\n_1': 0,\n",
       " 'char_\\n_2': 0,\n",
       " 'char_\\n_3': 0,\n",
       " 'char_\\x0b': 0,\n",
       " 'char_\\x0b_-1': 0,\n",
       " 'char_\\x0b_-2': 0,\n",
       " 'char_\\x0b_-3': 0,\n",
       " 'char_\\x0b_0': 0,\n",
       " 'char_\\x0b_1': 0,\n",
       " 'char_\\x0b_2': 0,\n",
       " 'char_\\x0b_3': 0,\n",
       " 'char_\\x0c': 0,\n",
       " 'char_\\x0c_-1': 0,\n",
       " 'char_\\x0c_-2': 0,\n",
       " 'char_\\x0c_-3': 0,\n",
       " 'char_\\x0c_0': 0,\n",
       " 'char_\\x0c_1': 0,\n",
       " 'char_\\x0c_2': 0,\n",
       " 'char_\\x0c_3': 0,\n",
       " 'char_\\r': 0,\n",
       " 'char_\\r_-1': 0,\n",
       " 'char_\\r_-2': 0,\n",
       " 'char_\\r_-3': 0,\n",
       " 'char_\\r_0': 0,\n",
       " 'char_\\r_1': 0,\n",
       " 'char_\\r_2': 0,\n",
       " 'char_\\r_3': 0,\n",
       " 'char_ ': 0,\n",
       " 'char_ _-1': 0,\n",
       " 'char_ _-2': 0,\n",
       " 'char_ _-3': 0,\n",
       " 'char_ _0': 0,\n",
       " 'char_ _1': 0,\n",
       " 'char_ _2': 0,\n",
       " 'char_ _3': 0,\n",
       " 'char_!': 0,\n",
       " 'char_!_-1': 0,\n",
       " 'char_!_-2': 0,\n",
       " 'char_!_-3': 0,\n",
       " 'char_!_0': 0,\n",
       " 'char_!_1': 0,\n",
       " 'char_!_2': 0,\n",
       " 'char_!_3': 0,\n",
       " 'char_\"': 0,\n",
       " 'char_\"_-1': 0,\n",
       " 'char_\"_-2': 0,\n",
       " 'char_\"_-3': 0,\n",
       " 'char_\"_0': 0,\n",
       " 'char_\"_1': 0,\n",
       " 'char_\"_2': 0,\n",
       " 'char_\"_3': 0,\n",
       " 'char_#': 0,\n",
       " 'char_#_-1': 0,\n",
       " 'char_#_-2': 0,\n",
       " 'char_#_-3': 0,\n",
       " 'char_#_0': 0,\n",
       " 'char_#_1': 0,\n",
       " 'char_#_2': 0,\n",
       " 'char_#_3': 0,\n",
       " 'char_$': 0,\n",
       " 'char_$_-1': 0,\n",
       " 'char_$_-2': 0,\n",
       " 'char_$_-3': 0,\n",
       " 'char_$_0': 0,\n",
       " 'char_$_1': 0,\n",
       " 'char_$_2': 0,\n",
       " 'char_$_3': 0,\n",
       " 'char_%': 0,\n",
       " 'char_%_-1': 0,\n",
       " 'char_%_-2': 0,\n",
       " 'char_%_-3': 0,\n",
       " 'char_%_0': 0,\n",
       " 'char_%_1': 0,\n",
       " 'char_%_2': 0,\n",
       " 'char_%_3': 0,\n",
       " 'char_&': 0,\n",
       " 'char_&_-1': 0,\n",
       " 'char_&_-2': 0,\n",
       " 'char_&_-3': 0,\n",
       " 'char_&_0': 0,\n",
       " 'char_&_1': 0,\n",
       " 'char_&_2': 0,\n",
       " 'char_&_3': 0,\n",
       " \"char_'\": 0,\n",
       " \"char_'_-1\": 0,\n",
       " \"char_'_-2\": 0,\n",
       " \"char_'_-3\": 0,\n",
       " \"char_'_0\": 0,\n",
       " \"char_'_1\": 0,\n",
       " \"char_'_2\": 0,\n",
       " \"char_'_3\": 0,\n",
       " 'char_(': 0,\n",
       " 'char_(_-1': 0,\n",
       " 'char_(_-2': 0,\n",
       " 'char_(_-3': 0,\n",
       " 'char_(_0': 0,\n",
       " 'char_(_1': 0,\n",
       " 'char_(_2': 0,\n",
       " 'char_(_3': 0,\n",
       " 'char_)': 0,\n",
       " 'char_)_-1': 0,\n",
       " 'char_)_-2': 0,\n",
       " 'char_)_-3': 0,\n",
       " 'char_)_0': 0,\n",
       " 'char_)_1': 0,\n",
       " 'char_)_2': 0,\n",
       " 'char_)_3': 0,\n",
       " 'char_*': 0,\n",
       " 'char_*_-1': 0,\n",
       " 'char_*_-2': 0,\n",
       " 'char_*_-3': 0,\n",
       " 'char_*_0': 0,\n",
       " 'char_*_1': 0,\n",
       " 'char_*_2': 0,\n",
       " 'char_*_3': 0,\n",
       " 'char_+': 0,\n",
       " 'char_+_-1': 0,\n",
       " 'char_+_-2': 0,\n",
       " 'char_+_-3': 0,\n",
       " 'char_+_0': 0,\n",
       " 'char_+_1': 0,\n",
       " 'char_+_2': 0,\n",
       " 'char_+_3': 0,\n",
       " 'char_,': 0,\n",
       " 'char_,_-1': 0,\n",
       " 'char_,_-2': 0,\n",
       " 'char_,_-3': 0,\n",
       " 'char_,_0': 0,\n",
       " 'char_,_1': 0,\n",
       " 'char_,_2': 0,\n",
       " 'char_,_3': 0,\n",
       " 'char_-': 0,\n",
       " 'char_-_-1': 0,\n",
       " 'char_-_-2': 0,\n",
       " 'char_-_-3': 0,\n",
       " 'char_-_0': 0,\n",
       " 'char_-_1': 0,\n",
       " 'char_-_2': 0,\n",
       " 'char_-_3': 0,\n",
       " 'char_.': 0,\n",
       " 'char_._-1': 1,\n",
       " 'char_._-2': 0,\n",
       " 'char_._-3': 0,\n",
       " 'char_._0': 0,\n",
       " 'char_._1': 0,\n",
       " 'char_._2': 0,\n",
       " 'char_._3': 0,\n",
       " 'char_/': 0,\n",
       " 'char_/_-1': 0,\n",
       " 'char_/_-2': 0,\n",
       " 'char_/_-3': 0,\n",
       " 'char_/_0': 0,\n",
       " 'char_/_1': 0,\n",
       " 'char_/_2': 0,\n",
       " 'char_/_3': 0,\n",
       " 'char_:': 0,\n",
       " 'char_:_-1': 0,\n",
       " 'char_:_-2': 0,\n",
       " 'char_:_-3': 0,\n",
       " 'char_:_0': 0,\n",
       " 'char_:_1': 0,\n",
       " 'char_:_2': 0,\n",
       " 'char_:_3': 0,\n",
       " 'char_;': 0,\n",
       " 'char_;_-1': 0,\n",
       " 'char_;_-2': 0,\n",
       " 'char_;_-3': 0,\n",
       " 'char_;_0': 0,\n",
       " 'char_;_1': 0,\n",
       " 'char_;_2': 0,\n",
       " 'char_;_3': 0,\n",
       " 'char_<': 0,\n",
       " 'char_<_-1': 0,\n",
       " 'char_<_-2': 0,\n",
       " 'char_<_-3': 0,\n",
       " 'char_<_0': 0,\n",
       " 'char_<_1': 0,\n",
       " 'char_<_2': 0,\n",
       " 'char_<_3': 0,\n",
       " 'char_=': 0,\n",
       " 'char_=_-1': 0,\n",
       " 'char_=_-2': 0,\n",
       " 'char_=_-3': 0,\n",
       " 'char_=_0': 0,\n",
       " 'char_=_1': 0,\n",
       " 'char_=_2': 0,\n",
       " 'char_=_3': 0,\n",
       " 'char_>': 0,\n",
       " 'char_>_-1': 0,\n",
       " 'char_>_-2': 0,\n",
       " 'char_>_-3': 0,\n",
       " 'char_>_0': 0,\n",
       " 'char_>_1': 0,\n",
       " 'char_>_2': 0,\n",
       " 'char_>_3': 0,\n",
       " 'char_?': 0,\n",
       " 'char_?_-1': 0,\n",
       " 'char_?_-2': 0,\n",
       " 'char_?_-3': 0,\n",
       " 'char_?_0': 0,\n",
       " 'char_?_1': 0,\n",
       " 'char_?_2': 0,\n",
       " 'char_?_3': 0,\n",
       " 'char_@': 0,\n",
       " 'char_@_-1': 0,\n",
       " 'char_@_-2': 0,\n",
       " 'char_@_-3': 0,\n",
       " 'char_@_0': 0,\n",
       " 'char_@_1': 0,\n",
       " 'char_@_2': 0,\n",
       " 'char_@_3': 0,\n",
       " 'char_[': 0,\n",
       " 'char_[_-1': 0,\n",
       " 'char_[_-2': 0,\n",
       " 'char_[_-3': 0,\n",
       " 'char_[_0': 0,\n",
       " 'char_[_1': 0,\n",
       " 'char_[_2': 0,\n",
       " 'char_[_3': 0,\n",
       " 'char_\\\\': 0,\n",
       " 'char_\\\\_-1': 0,\n",
       " 'char_\\\\_-2': 0,\n",
       " 'char_\\\\_-3': 0,\n",
       " 'char_\\\\_0': 0,\n",
       " 'char_\\\\_1': 0,\n",
       " 'char_\\\\_2': 0,\n",
       " 'char_\\\\_3': 0,\n",
       " 'char_]': 0,\n",
       " 'char_]_-1': 0,\n",
       " 'char_]_-2': 0,\n",
       " 'char_]_-3': 0,\n",
       " 'char_]_0': 0,\n",
       " 'char_]_1': 0,\n",
       " 'char_]_2': 0,\n",
       " 'char_]_3': 0,\n",
       " 'char_^': 0,\n",
       " 'char_^_-1': 0,\n",
       " 'char_^_-2': 0,\n",
       " 'char_^_-3': 0,\n",
       " 'char_^_0': 0,\n",
       " 'char_^_1': 0,\n",
       " 'char_^_2': 0,\n",
       " 'char_^_3': 0,\n",
       " 'char__': 0,\n",
       " 'char___-1': 0,\n",
       " 'char___-2': 0,\n",
       " 'char___-3': 0,\n",
       " 'char___0': 0,\n",
       " 'char___1': 0,\n",
       " 'char___2': 0,\n",
       " 'char___3': 0,\n",
       " 'char_`': 0,\n",
       " 'char_`_-1': 0,\n",
       " 'char_`_-2': 0,\n",
       " 'char_`_-3': 0,\n",
       " 'char_`_0': 0,\n",
       " 'char_`_1': 0,\n",
       " 'char_`_2': 0,\n",
       " 'char_`_3': 0,\n",
       " 'char_is_alpha_-1': 0,\n",
       " 'char_is_alpha_-2': 1,\n",
       " 'char_is_alpha_-3': 1,\n",
       " 'char_is_alpha_0': 0,\n",
       " 'char_is_alpha_1': 1,\n",
       " 'char_is_alpha_2': 1,\n",
       " 'char_is_alpha_3': 1,\n",
       " 'char_is_number_-1': 0,\n",
       " 'char_is_number_-2': 0,\n",
       " 'char_is_number_-3': 0,\n",
       " 'char_is_number_0': 0,\n",
       " 'char_is_number_1': 0,\n",
       " 'char_is_number_2': 0,\n",
       " 'char_is_number_3': 0,\n",
       " 'char_is_punct_-1': 1,\n",
       " 'char_is_punct_-2': 0,\n",
       " 'char_is_punct_-3': 0,\n",
       " 'char_is_punct_0': 0,\n",
       " 'char_is_punct_1': 0,\n",
       " 'char_is_punct_2': 0,\n",
       " 'char_is_punct_3': 0,\n",
       " 'char_is_whitespace_-1': 0,\n",
       " 'char_is_whitespace_-2': 0,\n",
       " 'char_is_whitespace_-3': 0,\n",
       " 'char_is_whitespace_0': 0,\n",
       " 'char_is_whitespace_1': 0,\n",
       " 'char_is_whitespace_2': 0,\n",
       " 'char_is_whitespace_3': 0,\n",
       " 'char_{': 0,\n",
       " 'char_{_-1': 0,\n",
       " 'char_{_-2': 0,\n",
       " 'char_{_-3': 0,\n",
       " 'char_{_0': 0,\n",
       " 'char_{_1': 0,\n",
       " 'char_{_2': 0,\n",
       " 'char_{_3': 0,\n",
       " 'char_|': 0,\n",
       " 'char_|_-1': 0,\n",
       " 'char_|_-2': 0,\n",
       " 'char_|_-3': 0,\n",
       " 'char_|_0': 0,\n",
       " 'char_|_1': 0,\n",
       " 'char_|_2': 0,\n",
       " 'char_|_3': 0,\n",
       " 'char_}': 0,\n",
       " 'char_}_-1': 0,\n",
       " 'char_}_-2': 0,\n",
       " 'char_}_-3': 0,\n",
       " 'char_}_0': 0,\n",
       " 'char_}_1': 0,\n",
       " 'char_}_2': 0,\n",
       " 'char_}_3': 0,\n",
       " 'char_~': 0,\n",
       " 'char_~_-1': 0,\n",
       " 'char_~_-2': 0,\n",
       " 'char_~_-3': 0,\n",
       " 'char_~_0': 0,\n",
       " 'char_~_1': 0,\n",
       " 'char_~_2': 0,\n",
       " 'char_~_3': 0}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_paragraph_start_features(\"This is a test.\\nThis is another test.\", 15, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Model parameters\n",
    "position_window_pre = 3\n",
    "position_window_post = 3\n",
    "\n",
    "# Setup feature and target data\n",
    "feature_data = []\n",
    "target_data = []\n",
    "\n",
    "# Test file\n",
    "file_name = '../../data/samples/lexpredict-contraxsuite-samples-master/agreements/employment/1000736_2005-05-10_AMENDMENT TO EMPLOYMENT AGREEMENT.txt'\n",
    "\n",
    "# Iterate through files and test\n",
    "file_buffer = open(file_name, \"rb\").read().decode(\"utf-8\")\n",
    "    \n",
    "for pos_id in range(len(file_buffer)):\n",
    "    if file_buffer[pos_id-1] in [\"\\n\", \"\\r\"]:\n",
    "        char_cat = unicodedata.category(file_buffer[pos_id])\n",
    "        if char_cat.startswith(\"N\") or char_cat.startswith(\"L\") or file_buffer[pos_id] in [\"(\", \"[\", \"]\", \")\"]:\n",
    "            #print((file_name, \"paragraph\", pos_id, file_buffer[(pos_id-10):pos_id] + \"|\" + file_buffer[pos_id:(pos_id+10)]))\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Model parameters\n",
    "position_window_pre = 5\n",
    "position_window_post = 5\n",
    "\n",
    "# Setup feature and target data\n",
    "feature_data = []\n",
    "target_data = []\n",
    "\n",
    "# Iterate through files and test\n",
    "for file_name in sorted(list(paragraph_break_positions.keys())):\n",
    "    file_buffer = open(file_name, \"rb\").read().decode(\"utf-8\")\n",
    "    \n",
    "    for pos_id in range(len(file_buffer)):\n",
    "        #if file_buffer[pos_id-1] in [\"\\n\", \"\\r\"]:\n",
    "        #char_cat = unicodedata.category(file_buffer[pos_id])\n",
    "        #if char_cat.startswith(\"N\") or char_cat.startswith(\"L\") or file_buffer[pos_id] in [\"(\", \"[\", \"]\", \")\"]:\n",
    "        if pos_id in paragraph_break_positions[file_name]:    \n",
    "            feature_data.append(build_paragraph_start_features(file_buffer, pos_id, position_window_pre, position_window_post))\n",
    "            target_data.append(1)\n",
    "            #print((file_name, \"paragraph\", pos_id, file_buffer[(pos_id-10):pos_id] + \"|\" + file_buffer[pos_id:(pos_id+10)]))\n",
    "        else:\n",
    "            if numpy.random.random() <= 0.1:\n",
    "                feature_data.append(build_paragraph_start_features(file_buffer, pos_id, position_window_pre, position_window_post))\n",
    "                target_data.append(0)\n",
    "                #print((file_name, \"random\", pos_id, file_buffer[(pos_id-10):(pos_id+10)]))\n",
    "        \n",
    "# Convert to DF\n",
    "feature_df = pandas.DataFrame(feature_data).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3895, 500)\n",
      "3895\n"
     ]
    }
   ],
   "source": [
    "print(feature_df.shape)\n",
    "print(len(target_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3760\n",
      "          1       0.97      1.00      0.99       135\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3895\n",
      "\n",
      "0.985401459854\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model_svc = sklearn.svm.SVC(kernel='linear', probability=True)\n",
    "model_svc.fit(feature_df, target_data)\n",
    "\n",
    "# Assess model\n",
    "predicted_svc = model_svc.predict(feature_df)\n",
    "print(sklearn.metrics.classification_report(target_data, predicted_svc))\n",
    "print(sklearn.metrics.f1_score(target_data, predicted_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3760\n",
      "          1       0.97      1.00      0.99       135\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3895\n",
      "\n",
      "0.985401459854\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model_pac = sklearn.linear_model.PassiveAggressiveClassifier()\n",
    "model_pac.fit(feature_df, target_data)\n",
    "\n",
    "# Assess model\n",
    "predicted_pac = model_pac.predict(feature_df)\n",
    "print(sklearn.metrics.classification_report(target_data, predicted_pac))\n",
    "print(sklearn.metrics.f1_score(target_data, predicted_pac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3760\n",
      "          1       0.99      1.00      0.99       135\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3895\n",
      "\n",
      "0.992647058824\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model_log = sklearn.linear_model.LogisticRegressionCV()\n",
    "model_log.fit(feature_df, target_data)\n",
    "\n",
    "# Assess model\n",
    "predicted_log = model_log.predict(feature_df)\n",
    "print(sklearn.metrics.classification_report(target_data, predicted_log))\n",
    "print(sklearn.metrics.f1_score(target_data, predicted_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3760\n",
      "          1       0.99      1.00      0.99       135\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3895\n",
      "\n",
      "0.992647058824\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model_sgd = sklearn.linear_model.SGDClassifier(loss=\"perceptron\")\n",
    "model_sgd.fit(feature_df, target_data)\n",
    "\n",
    "# Assess model\n",
    "predicted_sgd = model_sgd.predict(feature_df)\n",
    "print(sklearn.metrics.classification_report(target_data, predicted_sgd))\n",
    "print(sklearn.metrics.f1_score(target_data, predicted_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3760\n",
      "          1       0.99      1.00      1.00       135\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3895\n",
      "\n",
      "0.9963099631\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model_et = sklearn.ensemble.ExtraTreesClassifier(n_estimators=50)\n",
    "model_et.fit(feature_df, target_data)\n",
    "\n",
    "# Assess model\n",
    "predicted_et = model_et.predict(feature_df)\n",
    "print(sklearn.metrics.classification_report(target_data, predicted_et))\n",
    "print(sklearn.metrics.f1_score(target_data, predicted_et))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3760\n",
      "          1       0.99      1.00      1.00       135\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3895\n",
      "\n",
      "0.9963099631\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model_vote = sklearn.ensemble.VotingClassifier(estimators=[\n",
    "    ('log', model_log),\n",
    "    ('et', model_et)], voting='soft')\n",
    "model_vote.fit(feature_df, target_data)\n",
    "\n",
    "# Assess model\n",
    "predicted_vote = model_vote.predict(feature_df)\n",
    "print(sklearn.metrics.classification_report(target_data, predicted_vote))\n",
    "print(sklearn.metrics.f1_score(target_data, predicted_vote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paragraph_segmenter.pickle']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set production model\n",
    "from sklearn.externals import joblib\n",
    "model = model_log\n",
    "joblib.dump(model, \"paragraph_segmenter.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test OOS\n",
    "file_list = sorted(glob.glob(\"../../data/samples/lexpredict-contraxsuite-samples-master/agreements/employment/*.txt\"))\n",
    "test_lines = []\n",
    "test_feature_data = []\n",
    "\n",
    "for file_name in file_list[0:3]:\n",
    "    file_buffer = open(file_name, \"rb\").read().decode(\"utf-8\")\n",
    "    test_feature_data = []\n",
    "    for pos_id in range(min(10000, len(file_buffer))):\n",
    "        test_feature_data.append(build_paragraph_start_features(file_buffer, pos_id, position_window_pre, position_window_post))\n",
    "    test_feature_df = pandas.DataFrame(test_feature_data).fillna(-1)\n",
    "    test_predicted_breaks = model.predict_proba(test_feature_df)\n",
    "    break\n",
    "    \n",
    "\n",
    "# Predict page breaks\n",
    "#test_feature_df = pandas.DataFrame(test_feature_data).fillna(-1)\n",
    "#test_predicted_lines = model.predict_proba(test_feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pandas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-759e80c784c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicted_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_predicted_breaks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prob_false\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"prob_true\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mparagraph_breaks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prob_true\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraph_breaks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparagraph_breaks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pandas' is not defined"
     ]
    }
   ],
   "source": [
    "predicted_df = pandas.DataFrame(test_predicted_breaks, columns=[\"prob_false\", \"prob_true\"])\n",
    "paragraph_breaks = predicted_df.loc[predicted_df[\"prob_true\"] >= 0.5, :].index.tolist()\n",
    "\n",
    "for i in range(len(paragraph_breaks)-1):\n",
    "    p0 = paragraph_breaks[i]\n",
    "    p1 = paragraph_breaks[i+1]\n",
    "    paragraph = file_buffer[p0:p1].strip().replace(\"\\n\", \" \").replace(\"  \", \" \")\n",
    "    print(paragraph)\n",
    "    print(\"=\"*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
